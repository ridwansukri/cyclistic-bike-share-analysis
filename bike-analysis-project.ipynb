{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cyclistic Bike-Share Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Author: Muh Ridwan Sukri\n",
    "Last updated: January, 17th 2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This is a fictional case study as a capstone project of the __[Google Data Analytics Certificate](https://grow.google/certificates/data-analytics/)__\n",
    "My main goal is to show both my technical skills in SQL, R and Tableau as well as my data analyst approach to a case.\n",
    "The whole process could have been done entirely in Python without SQL or another BI Tools.\n",
    "In this case study, the six data analysis proces: ask, prepare, process, analyze, share, and act will be followed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Background\n",
    "I am a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago that features more than 5,800 bicycles and 600 docking stations. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, my team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, my team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve my recommendations, so they must be backed up with compelling data insights and professional data visualizations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Business Tasks\n",
    "1. Analyze Cyclistic historical bike trip data to identify trends and get some insights.\n",
    "2. Provide high quality recommendations for marketing analyst team."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Business Objectives\n",
    "1. How do annual members and casual riders use Cyclistic bikes differently?\n",
    "2. Why would casual riders buy Cyclistic annual memberships?\n",
    "3. How can Cyclistic use digital media to influence casual riders to become members?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deliverables\n",
    "1. A clear summary of the business task\n",
    "2. A description of all data sources used\n",
    "3. Documentation of any cleaning or manipulation of data\n",
    "4. A summary of analysis\n",
    "5. Supporting visualizations and key findings\n",
    "6. High-level content recommendations based on the analysis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Key stakeholders\n",
    "- Lily Moreno: The director of marketing and your manager.\n",
    "- Cyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy.\n",
    "- Cyclistic executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare\n",
    "\n",
    "In the Prepare phase, we identify the data being used and its limitations.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information on Data Source\n",
    "1. Cylistic dataset has been made available by Lyft Bikes and Scooters, LLC under this __[license](https://ride.divvybikes.com/data-license-agreement)__ and can be public accessed __[here](https://divvy-tripdata.s3.amazonaws.com/index.html)__\n",
    "2. We are using another dataset to get hourly average of Temperature, Precipitation, Relative Humidity, Wind Speed, and many variables from [Visual Crossing](https://www.visualcrossing.com/weather-data).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Crebility of Data\n",
    "The credibility and integrity of our data can be determined using the ROCCC system.\n",
    "- The data is __reliable__ — The dataset has a large sample size, reflecting the population size.\n",
    "- The data is __original__ — The dataset is generated by the first source (Lyft Bikes and Scooters, LLC) and not from Third Party.\n",
    "- The data is __comprehensive__ — There is no information about the participants, such as gender, age, health state, etc. This could mean that data was not randomised. If the data is biased, then the insights from the analysis will be unfair to all types of people. But it's understandable because this is public data so personal information must be hidden. Only an anonymous _ride_id_ identifies the ride.\n",
    "- The data is __current__ — it is relevant and up to date, thus indicating that the source refreshes its data regularly on each month.\n",
    "- The data is __cited__ — the source has been vetted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tools\n",
    "For this project, we are using some tools like:\n",
    "- Some tools from Google Cloud Platform for ETL process;\n",
    "- Python for data cleansing, EDA, and analysis;\n",
    "- Tableau for creating dashboard."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process\n",
    "We are using tools from GCS and Python to prepare and process the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ETL Process\n",
    "This is ETL structure that we used:\n",
    "![ETL Process](https://archive.org/download/etl-process/etl-process.png)\n",
    "\n",
    "The ETL process starts by downloading all files from the AWS bucket [\"divvy-tripdata\"](https://divvy-tripdata.s3.amazonaws.com/index.html), then we unzip all files and csv files from unzip is mounted to Google Cloud Storage using [GCSFuse](https://github.com/GoogleCloudPlatform/gcsfuse). Because the maximum uploaded file size from computer allowed by Bigquery is 100MB, so files must first be moved to the Cloud Storage Bucket and then uploaded to Bigquery.\n",
    "\n",
    "After uploading all the files to Bigquery, we perform the following [\"query\"](https://github.com/ridwansukri/cyclistic-bike-share-analysis/blob/main/bigquery-etl.sql). And then, we join the main dataset with dataframe (we uploaded in Bigquery) from NASA that contains average temperature, Temperature, Precipitation, Relative Humidity, and Wind Speed with this [\"query\"](https://github.com/ridwansukri/cyclistic-bike-share-analysis/blob/main/join-with-nasa.sql)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadata\n",
    "This dataset contains some variables that we used to perform analysis. Some variables are original from the dataset and the others are the results of the transformation from original variable.\n",
    "\n",
    "- ride_id: ID attached to each trip taken;\n",
    "- rideable_type: Type of bicycle used by the customer;\n",
    "- started_at: day and time trip started, in CST;\n",
    "- ended_at: day and time trip ended, in CST;\n",
    "- start_station_name: name of station where trip originated;\n",
    "- start_station_id: ID of station where trip originated;\n",
    "- end_station_name: name of station where trip terminated;\n",
    "- end_station_id: ID of station where trip terminated\n",
    "- start_lat: station latitude where trip originated;\n",
    "- start_lng: station longitude where trip originated;\n",
    "- end_lat: station latitude where trip terminated;\n",
    "- start_lng: station longitude where trip terminated;\n",
    "- member_casual: Type of customer that take the trip, casual or member;\n",
    "- trip_duration: time of trip in seconds;\n",
    "- YEAR: year when the trip started;\n",
    "- MO : Month when the trip started;\n",
    "- DY : Date when the trip started;\n",
    "- HR : Hour when the trip started;\n",
    "- day_start: the day when the trip started, starts from 1(Sunday) to 7 (Saturday).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries\n",
    "Packages that we used are installed and aliased for easy reading."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from google.cloud import bigquery #get data from Bigquery\n",
    "import os # interacting with our OS\n",
    "from google.cloud.exceptions import NotFound\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd # data structure and data analysis\n",
    "import numpy as np # data arrays\n",
    "import matplotlib.pyplot as plt # data visualization library\n",
    "import plotly.express as px #data visualization library\n",
    "import seaborn as sns #data visualization library\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing dataset\n",
    "We import dataset from Bigquery and put in our notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/aspir/Desktop/Divvy/acoustic-portal-322707-496a5c838490.json'\n",
    "# initiates BQ service\n",
    "bigquery_client = bigquery.Client()\n",
    "# Write Query on BQ\n",
    "QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  `bike_dataset.bike_trip`\n",
    ";\n",
    "  \"\"\"\n",
    "# Run the query and write result to a pandas data frame\n",
    "Query_Results = bigquery_client.query(QUERY)\n",
    "df = Query_Results.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning and Manipulation\n",
    "Steps\n",
    "\n",
    "- Observe and familiarize with data;\n",
    "- Check for null or missing values;\n",
    "- Perform sanity check of data\n",
    "\n",
    "Using head function to show first 10 rows and familiarise with the data. We create copy of dataframe as a checkpoint so if there is a wrong step that changes the dataframe to be unwanted, we don't need to run the syntax from the beginning, just run it from the checkpoint."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            ride_id  rideable_type                started_at  \\\n0  B06B3C2BCB553751   classic_bike 2022-07-09 13:03:48+00:00   \n1  0EEF17FE68115937   classic_bike 2022-12-03 12:00:03+00:00   \n2  CA5C3C61BD9D0763   classic_bike 2022-10-08 05:30:21+00:00   \n3  54280A6BA04278FA  electric_bike 2022-05-28 11:16:56+00:00   \n4  39B0C56254EE1E36   classic_bike 2022-01-22 19:56:32+00:00   \n\n                   ended_at         start_station_name start_station_id  \\\n0 2022-07-09 13:09:26+00:00       Wells St & Walton St     TA1306000011   \n1 2022-12-03 12:07:47+00:00  Halsted St & Clybourn Ave              331   \n2 2022-10-08 05:37:11+00:00      Dayton St & North Ave            13058   \n3 2022-05-28 11:38:44+00:00      LaSalle Dr & Huron St     KP1705001026   \n4 2022-01-22 20:05:57+00:00               Eckhart Park            13289   \n\n             end_station_name end_station_id  start_lat  start_lng    end_lat  \\\n0  Larrabee St & Kingsbury St   TA1306000009  41.899930 -87.634430  41.897764   \n1  Larrabee St & Kingsbury St   TA1306000009  41.909668 -87.648128  41.897764   \n2  Larrabee St & Kingsbury St   TA1306000009  41.910578 -87.649422  41.897764   \n3  Larrabee St & Kingsbury St   TA1306000009  41.894739 -87.632186  41.897764   \n4         Orleans St & Elm St   TA1306000006  41.896373 -87.660984  41.902924   \n\n     end_lng member_casual  trip_duration  YEAR  MO  DY  HR  day_start  \n0 -87.642884        casual            338  2022   7   9  13          7  \n1 -87.642884        member            464  2022  12   3  12          7  \n2 -87.642884        casual            410  2022  10   8   5          7  \n3 -87.642884        casual           1308  2022   5  28  11          7  \n4 -87.637715        member            565  2022   1  22  19          7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>rideable_type</th>\n      <th>started_at</th>\n      <th>ended_at</th>\n      <th>start_station_name</th>\n      <th>start_station_id</th>\n      <th>end_station_name</th>\n      <th>end_station_id</th>\n      <th>start_lat</th>\n      <th>start_lng</th>\n      <th>end_lat</th>\n      <th>end_lng</th>\n      <th>member_casual</th>\n      <th>trip_duration</th>\n      <th>YEAR</th>\n      <th>MO</th>\n      <th>DY</th>\n      <th>HR</th>\n      <th>day_start</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B06B3C2BCB553751</td>\n      <td>classic_bike</td>\n      <td>2022-07-09 13:03:48+00:00</td>\n      <td>2022-07-09 13:09:26+00:00</td>\n      <td>Wells St &amp; Walton St</td>\n      <td>TA1306000011</td>\n      <td>Larrabee St &amp; Kingsbury St</td>\n      <td>TA1306000009</td>\n      <td>41.899930</td>\n      <td>-87.634430</td>\n      <td>41.897764</td>\n      <td>-87.642884</td>\n      <td>casual</td>\n      <td>338</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>13</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0EEF17FE68115937</td>\n      <td>classic_bike</td>\n      <td>2022-12-03 12:00:03+00:00</td>\n      <td>2022-12-03 12:07:47+00:00</td>\n      <td>Halsted St &amp; Clybourn Ave</td>\n      <td>331</td>\n      <td>Larrabee St &amp; Kingsbury St</td>\n      <td>TA1306000009</td>\n      <td>41.909668</td>\n      <td>-87.648128</td>\n      <td>41.897764</td>\n      <td>-87.642884</td>\n      <td>member</td>\n      <td>464</td>\n      <td>2022</td>\n      <td>12</td>\n      <td>3</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CA5C3C61BD9D0763</td>\n      <td>classic_bike</td>\n      <td>2022-10-08 05:30:21+00:00</td>\n      <td>2022-10-08 05:37:11+00:00</td>\n      <td>Dayton St &amp; North Ave</td>\n      <td>13058</td>\n      <td>Larrabee St &amp; Kingsbury St</td>\n      <td>TA1306000009</td>\n      <td>41.910578</td>\n      <td>-87.649422</td>\n      <td>41.897764</td>\n      <td>-87.642884</td>\n      <td>casual</td>\n      <td>410</td>\n      <td>2022</td>\n      <td>10</td>\n      <td>8</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54280A6BA04278FA</td>\n      <td>electric_bike</td>\n      <td>2022-05-28 11:16:56+00:00</td>\n      <td>2022-05-28 11:38:44+00:00</td>\n      <td>LaSalle Dr &amp; Huron St</td>\n      <td>KP1705001026</td>\n      <td>Larrabee St &amp; Kingsbury St</td>\n      <td>TA1306000009</td>\n      <td>41.894739</td>\n      <td>-87.632186</td>\n      <td>41.897764</td>\n      <td>-87.642884</td>\n      <td>casual</td>\n      <td>1308</td>\n      <td>2022</td>\n      <td>5</td>\n      <td>28</td>\n      <td>11</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39B0C56254EE1E36</td>\n      <td>classic_bike</td>\n      <td>2022-01-22 19:56:32+00:00</td>\n      <td>2022-01-22 20:05:57+00:00</td>\n      <td>Eckhart Park</td>\n      <td>13289</td>\n      <td>Orleans St &amp; Elm St</td>\n      <td>TA1306000006</td>\n      <td>41.896373</td>\n      <td>-87.660984</td>\n      <td>41.902924</td>\n      <td>-87.637715</td>\n      <td>member</td>\n      <td>565</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>22</td>\n      <td>19</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View top few rows of result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Create a copy of dataframe\n",
    "bike_df = df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we check all column names, column types, and total rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5667907 entries, 0 to 5667906\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Dtype              \n",
      "---  ------              -----              \n",
      " 0   ride_id             object             \n",
      " 1   rideable_type       object             \n",
      " 2   started_at          datetime64[ns, UTC]\n",
      " 3   ended_at            datetime64[ns, UTC]\n",
      " 4   start_station_name  object             \n",
      " 5   start_station_id    object             \n",
      " 6   end_station_name    object             \n",
      " 7   end_station_id      object             \n",
      " 8   start_lat           float64            \n",
      " 9   start_lng           float64            \n",
      " 10  end_lat             float64            \n",
      " 11  end_lng             float64            \n",
      " 12  member_casual       object             \n",
      " 13  trip_duration       int64              \n",
      " 14  YEAR                int64              \n",
      " 15  MO                  int64              \n",
      " 16  DY                  int64              \n",
      " 17  HR                  int64              \n",
      " 18  day_start           int64              \n",
      "dtypes: datetime64[ns, UTC](2), float64(4), int64(6), object(7)\n",
      "memory usage: 821.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking all column types\n",
    "print(bike_df.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are several column types that need to be changed.\n",
    "Lily Moreno asked to retrieve data in the last 12 months. We will check the data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min   2021-12-31 18:00:21+00:00\n",
      "max   2022-12-31 17:59:57+00:00\n",
      "Name: started_at, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "# Check time ranges of bike_df\n",
    "date_min_max = bike_df['started_at'].agg(['min', 'max'])\n",
    "print(date_min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe contains the last 12 months.\n",
    "Then, find out whether there is any null or missing values in `bike_df` dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                0.000000\n",
      "rideable_type          0.000000\n",
      "started_at             0.000000\n",
      "ended_at               0.000000\n",
      "start_station_name    14.700153\n",
      "start_station_id      14.700153\n",
      "end_station_name      15.753293\n",
      "end_station_id        15.753293\n",
      "start_lat              0.000000\n",
      "start_lng              0.000000\n",
      "end_lat                0.103319\n",
      "end_lng                0.103319\n",
      "member_casual          0.000000\n",
      "trip_duration          0.000000\n",
      "YEAR                   0.000000\n",
      "MO                     0.000000\n",
      "DY                     0.000000\n",
      "HR                     0.000000\n",
      "day_start              0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check percentage of null values\n",
    "print(bike_df.isnull().mean() * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We found some columns had missing value. We will mark to the next manipulation process.\n",
    "Then we check whether there are duplicate rows in `bike_df` dataframe by checking the `ride_id` column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [ride_id, rideable_type, started_at, ended_at, start_station_name, start_station_id, end_station_name, end_station_id, start_lat, start_lng, end_lat, end_lng, member_casual, trip_duration, YEAR, MO, DY, HR, day_start]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>rideable_type</th>\n      <th>started_at</th>\n      <th>ended_at</th>\n      <th>start_station_name</th>\n      <th>start_station_id</th>\n      <th>end_station_name</th>\n      <th>end_station_id</th>\n      <th>start_lat</th>\n      <th>start_lng</th>\n      <th>end_lat</th>\n      <th>end_lng</th>\n      <th>member_casual</th>\n      <th>trip_duration</th>\n      <th>YEAR</th>\n      <th>MO</th>\n      <th>DY</th>\n      <th>HR</th>\n      <th>day_start</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get duplicate rows\n",
    "duplicates = bike_df.duplicated(subset=['ride_id'])\n",
    "bike_df[duplicates]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From above observation, we notice that:\n",
    "1. There is no duplicate rows\n",
    "2. Dataframe has 5731898 rows and 23 columns\n",
    "3. `rideable_type`, `start_station_name`, `start_station_id`, `end_station_name`, `end_station_id`, `member_casual`, `year`, `month`, `date`, `hour`, `day_start` columns type need to be converted to `category` dtype\n",
    "4. Some columns need to rename\n",
    "5. Some columns associated with stations have null values with range of 14-16%\n",
    "6. `end_lat` and `end_lng` have 1% of null values\n",
    "\n",
    "Following data manipulation is performed:\n",
    "- Rename some column names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "bike_df = bike_df.rename(columns={'rideable_type':'bike_type', 'member_casual':'customer_type', 'MO':'month',\n",
    "                                  'DY':'date', 'YEAR':'year', 'HR':'hour'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Convert column types to right type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Define a category column converter function\n",
    "def convert_to_category(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype('category')\n",
    "    return df\n",
    "\n",
    "# Define a string column converter function\n",
    "def convert_to_string(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype('string')\n",
    "    return df\n",
    "\n",
    "# Define a int64 column converter function\n",
    "def convert_to_int(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype(int)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# call converter column type function to category type\n",
    "bike_df = convert_to_category(bike_df, ['bike_type', 'customer_type', 'day_start', 'year', 'month', 'date', 'hour'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                            object\n",
      "bike_type                        category\n",
      "started_at            datetime64[ns, UTC]\n",
      "ended_at              datetime64[ns, UTC]\n",
      "start_station_name                 object\n",
      "start_station_id                   object\n",
      "end_station_name                   object\n",
      "end_station_id                     object\n",
      "start_lat                         float64\n",
      "start_lng                         float64\n",
      "end_lat                           float64\n",
      "end_lng                           float64\n",
      "customer_type                    category\n",
      "trip_duration                       int64\n",
      "year                             category\n",
      "month                            category\n",
      "date                             category\n",
      "hour                             category\n",
      "day_start                        category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking again data types\n",
    "print(bike_df.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Checking unique values using simple function. We noticed \"docked_bike\" just has 3% of total values in `bike_type` column. As our judgement, \"docked_bike \"is new version of \"classic bike\" which \"docked_bike\" has a portable lock so if you want to secure the bike it can be locked anywhere (no need to bring it to the near station)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classic_bike', 'electric_bike', 'docked_bike']\n",
      "Categories (3, object): ['classic_bike', 'docked_bike', 'electric_bike']\n",
      "['casual', 'member']\n",
      "Categories (2, object): ['casual', 'member']\n",
      "[7, 6, 1, 2, 3, 4, 5]\n",
      "Categories (7, int64): [1, 2, 3, 4, 5, 6, 7]\n",
      "[2022, 2021]\n",
      "Categories (2, int64): [2021, 2022]\n",
      "[7, 12, 10, 5, 1, ..., 11, 3, 9, 6, 2]\n",
      "Length: 12\n",
      "Categories (12, int64): [1, 2, 3, 4, ..., 9, 10, 11, 12]\n",
      "[9, 3, 8, 28, 22, ..., 4, 21, 7, 12, 26]\n",
      "Length: 31\n",
      "Categories (31, int64): [1, 2, 3, 4, ..., 28, 29, 30, 31]\n",
      "[13, 12, 5, 11, 19, ..., 2, 3, 6, 7, 4]\n",
      "Length: 24\n",
      "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Checking unique values\n",
    "for col in ['bike_type','customer_type', 'day_start', 'year', 'month', 'date', 'hour']:\n",
    "    print(bike_df[col].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electric_bike    0.509746\n",
      "classic_bike     0.458939\n",
      "docked_bike      0.031315\n",
      "Name: bike_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking percentage of each value on bike_type column\n",
    "print(bike_df['bike_type'].value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike type:  ['classic_bike', 'electric_bike']\n",
      "Categories (2, object): ['classic_bike', 'electric_bike']\n"
     ]
    }
   ],
   "source": [
    "# Change 'docked_bike' to 'classic_bike'\n",
    "bike_df['bike_type'] = bike_df['bike_type'].replace(['docked_bike'],'classic_bike')\n",
    "print('bike type: ', bike_df['bike_type'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Transform all values in \"bike_type\" and \"customer_type\" as title case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electric Bike    2889191\n",
      "Classic Bike     2778716\n",
      "Name: bike_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert values in bike_type as title case and remove underscore\n",
    "bike_df['bike_type'] = bike_df['bike_type'].str.title().replace('_', ' ', regex=True)\n",
    "print(bike_df['bike_type'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Member    3345771\n",
      "Casual    2322136\n",
      "Name: customer_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert values in customer_type as title case and remove underscore\n",
    "bike_df['customer_type'] = bike_df.customer_type.str.title()\n",
    "print(bike_df['customer_type'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `start_station_name` and `end_station_name` end with 1.3% unusual symbols , such as *, (TEMP), and TEST symbols. We need to remove it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Create variable with unusual symbols\n",
    "search = ('*', '(Temp)', 'TEST')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.984342\n",
      "True     0.015658\n",
      "Name: start_station_name, dtype: float64\n",
      "False    0.983615\n",
      "True     0.016385\n",
      "Name: end_station_name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking start_station_name and end_station_name whether have unusual symbols\n",
    "print(bike_df[\"start_station_name\"].str.endswith(search).value_counts(normalize=True))\n",
    "print(bike_df[\"end_station_name\"].str.endswith(search).value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Remove unusual symbols\n",
    "bike_df['start_station_name'] = bike_df['start_station_name'].str.rstrip('(*) (Temp) (TEST)')\n",
    "bike_df['end_station_name'] = bike_df['end_station_name'].str.rstrip('(*) (Temp) (TEST)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    1.0\n",
      "Name: start_station_name, dtype: float64\n",
      "False    1.0\n",
      "Name: end_station_name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking again both columns if still contains unusual symbols\n",
    "print(bike_df[\"start_station_name\"].str.endswith(search).value_counts(normalize=True))\n",
    "print(bike_df[\"end_station_name\"].str.endswith(search).value_counts(normalize=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We need to change all value of `day_start` column to make it easier to read. Value 1 is represented by \"Sunday\" and 7 by \"Saturday\" in a row."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Create mapping dictionary and replace\n",
    "mapping = {1:'Sunday', 2:'Monday', 3:'Tuesday', 4:'Wednesday', 5:'Thursday', 6:'Friday', 7:'Saturday'}\n",
    "bike_df['day_start'] = bike_df['day_start'].replace(mapping).astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturday     915226\n",
      "Thursday     841591\n",
      "Friday       803222\n",
      "Wednesday    798223\n",
      "Tuesday      782372\n",
      "Sunday       776259\n",
      "Monday       751014\n",
      "Name: day_start, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the replaced values\n",
    "print(bike_df['day_start'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Remove UTC offset in `started_at` and `ended_at` columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Remove UTC offset in started_at and ended_at column\n",
    "bike_df['started_at'] = pd.to_datetime(bike_df['started_at']).dt.tz_convert(None)\n",
    "bike_df['ended_at'] = pd.to_datetime(bike_df['ended_at']).dt.tz_convert(None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           started_at            ended_at\n",
      "0 2022-07-09 13:03:48 2022-07-09 13:09:26\n",
      "1 2022-12-03 12:00:03 2022-12-03 12:07:47\n",
      "2 2022-10-08 05:30:21 2022-10-08 05:37:11\n",
      "3 2022-05-28 11:16:56 2022-05-28 11:38:44\n",
      "4 2022-01-22 19:56:32 2022-01-22 20:05:57\n"
     ]
    }
   ],
   "source": [
    "# Checking after remove UTC offset\n",
    "print(bike_df[['started_at', 'ended_at']].head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We remove any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it was secure). And From [this](https://gov.publicstuff.com/content/kb/529/view/52885) website, if the bike has not been returned and correctly docked at a station after 24 hours, the bike is considered stolen and we need to remove from our data because this ride is invalid."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min       61\n",
      "max    86396\n",
      "Name: trip_duration, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rides when the rides less than 60 seconds and more than 24 hours\n",
    "bike_df = bike_df[(bike_df['trip_duration'] > 60) & (bike_df['trip_duration'] < 86400)]\n",
    "\n",
    "# Check again\n",
    "duration_min_max = bike_df['trip_duration'].agg(['min', 'max'])\n",
    "print(duration_min_max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We change the `trip_duration` column from seconds to minutes for easy to read."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5.633333\n",
      "1     7.733333\n",
      "2     6.833333\n",
      "3    21.800000\n",
      "4     9.416667\n",
      "Name: trip_duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#convert trip_duration from seconds to minutes\n",
    "bike_df['trip_duration'] = bike_df['trip_duration'].div(60)\n",
    "# Check after convert\n",
    "print(bike_df['trip_duration'].head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We drop end_lat column which had null values. Our assumption that ride is invalid and maybe tke bike get stolen, if the app can get the starting coordinates, it should also be able to get the ending coordinates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                0.000000\n",
      "bike_type              0.000000\n",
      "started_at             0.000000\n",
      "ended_at               0.000000\n",
      "start_station_name    14.475610\n",
      "start_station_id      14.475610\n",
      "end_station_name      15.241805\n",
      "end_station_id        15.241805\n",
      "start_lat              0.000000\n",
      "start_lng              0.000000\n",
      "end_lat                0.000000\n",
      "end_lng                0.000000\n",
      "customer_type          0.000000\n",
      "trip_duration          0.000000\n",
      "year                   0.000000\n",
      "month                  0.000000\n",
      "date                   0.000000\n",
      "hour                   0.000000\n",
      "day_start              0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop missing values in end_lat and end_lng columns\n",
    "bike_df = bike_df.dropna(subset = ['end_lat', 'end_lng'])\n",
    "# Check percentage of null values\n",
    "print(bike_df.isnull().mean() * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The rest of the columns that still have null values will be filled with \"Not Available\". We're assuming the bike starts or ends at a non-station, or the app has trouble getting the station name."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values with Not Available\n",
    "bike_df[['start_station_name', 'start_station_id', 'end_station_name', 'end_station_id']] = bike_df[['start_station_name', 'start_station_id', 'end_station_name', 'end_station_id']].fillna(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id               0.0\n",
      "bike_type             0.0\n",
      "started_at            0.0\n",
      "ended_at              0.0\n",
      "start_station_name    0.0\n",
      "start_station_id      0.0\n",
      "end_station_name      0.0\n",
      "end_station_id        0.0\n",
      "start_lat             0.0\n",
      "start_lng             0.0\n",
      "end_lat               0.0\n",
      "end_lng               0.0\n",
      "customer_type         0.0\n",
      "trip_duration         0.0\n",
      "year                  0.0\n",
      "month                 0.0\n",
      "date                  0.0\n",
      "hour                  0.0\n",
      "day_start             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check percentage of null values\n",
    "print(bike_df.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Create `season` column based on `started_at` column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# create date_offset column\n",
    "bike_df['date_offset'] = (bike_df['started_at'].dt.month*100 + bike_df['started_at'].dt.day - 320)%1300\n",
    "\n",
    "#Categorizing the season based on date_offset\n",
    "bike_df['season'] = pd.cut(bike_df['date_offset'], [0, 300, 602, 900, 1300],\n",
    "                      labels=['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "\n",
    "# call our function to convert as category type\n",
    "bike_df = convert_to_category(bike_df, ['season'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Summer', 'Fall', 'Spring', 'Winter', NaN]\n",
      "Categories (4, object): ['Spring' < 'Summer' < 'Fall' < 'Winter']\n"
     ]
    }
   ],
   "source": [
    "# Checking Season value that created with above syntax\n",
    "print(bike_df['season'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min   2022-03-20 00:00:04\n",
      "max   2022-03-20 23:59:59\n",
      "Name: started_at, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Investigate season column that contains missing value (NaN)\n",
    "nan_in_col = bike_df[bike_df['season'].isna()]\n",
    "# Check range of started ride in season's missing value\n",
    "date_min_max = nan_in_col['started_at'].agg(['min', 'max'])\n",
    "print(date_min_max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# 20 March in Chicago is spring, fill missing values with spring\n",
    "bike_df['season'] = bike_df['season'].fillna(\"Spring\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Summer', 'Fall', 'Spring', 'Winter']\n",
      "Categories (4, object): ['Spring' < 'Summer' < 'Fall' < 'Winter']\n"
     ]
    }
   ],
   "source": [
    "# Check again unique value of season column\n",
    "print(bike_df['season'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Drop date_offset column that we don't use anymore\n",
    "bike_df = bike_df.drop('date_offset', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Then, we change values in `month` from number to month name;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Convert month number\n",
    "mapping = {1:'January', 2:'February', 3:'March', 4:'April', 5:'May', 6:'June',\n",
    "           7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Creating new `hour` column based on `started_at` column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Get hour based on started_at column\n",
    "bike_df['hour'] = bike_df.started_at.apply(lambda x: x.hour)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- In this final cleaning step, we need to change the imprecise column types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                       object\n",
      "bike_type                     object\n",
      "started_at            datetime64[ns]\n",
      "ended_at              datetime64[ns]\n",
      "start_station_name            object\n",
      "start_station_id              object\n",
      "end_station_name              object\n",
      "end_station_id                object\n",
      "start_lat                    float64\n",
      "start_lng                    float64\n",
      "end_lat                      float64\n",
      "end_lng                      float64\n",
      "customer_type                 object\n",
      "trip_duration                float64\n",
      "year                        category\n",
      "month                       category\n",
      "date                        category\n",
      "hour                           int64\n",
      "day_start                   category\n",
      "season                      category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check again data types\n",
    "print(bike_df.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# call function to convert column as category type\n",
    "bike_df = convert_to_category(bike_df, ['bike_type', 'start_station_name', 'start_station_id',\n",
    "                                        'end_station_name', 'end_station_id', 'customer_type', 'month', 'hour'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- In analyze step, we are using final dataframe `clean_bike`. We drop columns that we will not use in the analysis process;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# Drop column and creating new dataframe\n",
    "clean_bike = bike_df.drop(columns=['ride_id', 'start_station_id', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng',])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining Main Dataframe with Weather Data\n",
    "After we clean main dataframe, we will combine with weather data that we cleaned [here](https://app.datacamp.com/workspace/w/750fac7a-4b4a-45e8-9a60-8996b4a46dfd)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/aspir/Desktop/Divvy/acoustic-portal-322707-496a5c838490.json'\n",
    "# initiates BQ service\n",
    "bigquery_client = bigquery.Client()\n",
    "# Write Query on BQ\n",
    "QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  `bike_dataset.clean_weather`\n",
    ";\n",
    "  \"\"\"\n",
    "# Run the query and write result to a pandas data frame\n",
    "Query_Results = bigquery_client.query(QUERY)\n",
    "weather_df = Query_Results.to_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "   MO  DY  HR  temp  feelslike  dew  humidity  precip  precipprob  snow  \\\n0   1   1   0   5.0        0.8  2.5     84.14     0.0           0   0.0   \n1   1   1   1   4.2       -0.7  2.2     86.96     0.0           0   0.0   \n2   1   1   2   3.5       -0.4  1.5     86.89     0.0           0   0.0   \n3   1   1   3   3.6       -0.7  1.3     85.10     0.0           0   0.0   \n4   1   1   4   3.5       -1.1  0.8     82.72     0.0           0   0.0   \n\n   snowdepth  windspeed  winddir  sealevelpressure  cloudcover  visibility  \\\n0        0.0       22.3     12.0            1006.7       100.0         8.6   \n1        0.0       26.3     15.0            1007.1       100.0         5.3   \n2        0.0       16.7      5.0            1007.9       100.0         5.3   \n3        0.0       19.9     11.0            1008.5       100.0         9.1   \n4        0.0       22.6     10.0            1008.4       100.0        13.6   \n\n  condition  \n0    Cloudy  \n1    Cloudy  \n2    Cloudy  \n3    Cloudy  \n4    Cloudy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MO</th>\n      <th>DY</th>\n      <th>HR</th>\n      <th>temp</th>\n      <th>feelslike</th>\n      <th>dew</th>\n      <th>humidity</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>condition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>0.8</td>\n      <td>2.5</td>\n      <td>84.14</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.3</td>\n      <td>12.0</td>\n      <td>1006.7</td>\n      <td>100.0</td>\n      <td>8.6</td>\n      <td>Cloudy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.2</td>\n      <td>-0.7</td>\n      <td>2.2</td>\n      <td>86.96</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>26.3</td>\n      <td>15.0</td>\n      <td>1007.1</td>\n      <td>100.0</td>\n      <td>5.3</td>\n      <td>Cloudy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>-0.4</td>\n      <td>1.5</td>\n      <td>86.89</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.7</td>\n      <td>5.0</td>\n      <td>1007.9</td>\n      <td>100.0</td>\n      <td>5.3</td>\n      <td>Cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3.6</td>\n      <td>-0.7</td>\n      <td>1.3</td>\n      <td>85.10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>19.9</td>\n      <td>11.0</td>\n      <td>1008.5</td>\n      <td>100.0</td>\n      <td>9.1</td>\n      <td>Cloudy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3.5</td>\n      <td>-1.1</td>\n      <td>0.8</td>\n      <td>82.72</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.6</td>\n      <td>10.0</td>\n      <td>1008.4</td>\n      <td>100.0</td>\n      <td>13.6</td>\n      <td>Cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check weather data\n",
    "weather_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# Rename Weather column name\n",
    "weather_df = weather_df.rename(columns={'MO':'month', 'DY':'date', 'HR':'hour'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Left join clean_bike with weather dataframe\n",
    "clean_bike = pd.merge(clean_bike, weather_df, on=['month', 'date', 'hour'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "      bike_type          started_at            ended_at  \\\n0  Classic Bike 2022-07-09 13:03:48 2022-07-09 13:09:26   \n1  Classic Bike 2022-07-09 13:35:40 2022-07-09 14:12:38   \n2  Classic Bike 2022-07-09 13:28:48 2022-07-09 13:41:07   \n3  Classic Bike 2022-07-09 13:31:14 2022-07-09 14:21:48   \n4  Classic Bike 2022-07-09 13:30:42 2022-07-09 13:40:39   \n\n                   start_station_name               end_station_name  \\\n0                Wells St & Walton St     Larrabee St & Kingsbury St   \n1  DuSable Lake Shore Dr & North Blvd          Michigan Ave & 8th St   \n2      Central Park Ave & Elbridge Av  Avondale Ave & Irving Park Rd   \n3             Lake Park Ave & 56th St          Michigan Ave & 8th St   \n4           Wabash Ave & Roosevelt Rd                  Shedd Aquariu   \n\n  customer_type  trip_duration  year  month  date  ...  precip precipprob  \\\n0        Casual       5.633333  2022      7     9  ...     0.0          0   \n1        Casual      36.966667  2022      7     9  ...     0.0          0   \n2        Casual      12.316667  2022      7     9  ...     0.0          0   \n3        Casual      50.566667  2022      7     9  ...     0.0          0   \n4        Casual       9.950000  2022      7     9  ...     0.0          0   \n\n  snow  snowdepth  windspeed  winddir  sealevelpressure  cloudcover  \\\n0  0.0        0.0       22.1     64.0            1021.4        24.2   \n1  0.0        0.0       22.1     64.0            1021.4        24.2   \n2  0.0        0.0       22.1     64.0            1021.4        24.2   \n3  0.0        0.0       22.1     64.0            1021.4        24.2   \n4  0.0        0.0       22.1     64.0            1021.4        24.2   \n\n   visibility          condition  \n0        16.0  Partly Cloudy Day  \n1        16.0  Partly Cloudy Day  \n2        16.0  Partly Cloudy Day  \n3        16.0  Partly Cloudy Day  \n4        16.0  Partly Cloudy Day  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike_type</th>\n      <th>started_at</th>\n      <th>ended_at</th>\n      <th>start_station_name</th>\n      <th>end_station_name</th>\n      <th>customer_type</th>\n      <th>trip_duration</th>\n      <th>year</th>\n      <th>month</th>\n      <th>date</th>\n      <th>...</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>condition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Classic Bike</td>\n      <td>2022-07-09 13:03:48</td>\n      <td>2022-07-09 13:09:26</td>\n      <td>Wells St &amp; Walton St</td>\n      <td>Larrabee St &amp; Kingsbury St</td>\n      <td>Casual</td>\n      <td>5.633333</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.1</td>\n      <td>64.0</td>\n      <td>1021.4</td>\n      <td>24.2</td>\n      <td>16.0</td>\n      <td>Partly Cloudy Day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Classic Bike</td>\n      <td>2022-07-09 13:35:40</td>\n      <td>2022-07-09 14:12:38</td>\n      <td>DuSable Lake Shore Dr &amp; North Blvd</td>\n      <td>Michigan Ave &amp; 8th St</td>\n      <td>Casual</td>\n      <td>36.966667</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.1</td>\n      <td>64.0</td>\n      <td>1021.4</td>\n      <td>24.2</td>\n      <td>16.0</td>\n      <td>Partly Cloudy Day</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Classic Bike</td>\n      <td>2022-07-09 13:28:48</td>\n      <td>2022-07-09 13:41:07</td>\n      <td>Central Park Ave &amp; Elbridge Av</td>\n      <td>Avondale Ave &amp; Irving Park Rd</td>\n      <td>Casual</td>\n      <td>12.316667</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.1</td>\n      <td>64.0</td>\n      <td>1021.4</td>\n      <td>24.2</td>\n      <td>16.0</td>\n      <td>Partly Cloudy Day</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Classic Bike</td>\n      <td>2022-07-09 13:31:14</td>\n      <td>2022-07-09 14:21:48</td>\n      <td>Lake Park Ave &amp; 56th St</td>\n      <td>Michigan Ave &amp; 8th St</td>\n      <td>Casual</td>\n      <td>50.566667</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.1</td>\n      <td>64.0</td>\n      <td>1021.4</td>\n      <td>24.2</td>\n      <td>16.0</td>\n      <td>Partly Cloudy Day</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Classic Bike</td>\n      <td>2022-07-09 13:30:42</td>\n      <td>2022-07-09 13:40:39</td>\n      <td>Wabash Ave &amp; Roosevelt Rd</td>\n      <td>Shedd Aquariu</td>\n      <td>Casual</td>\n      <td>9.950000</td>\n      <td>2022</td>\n      <td>7</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.1</td>\n      <td>64.0</td>\n      <td>1021.4</td>\n      <td>24.2</td>\n      <td>16.0</td>\n      <td>Partly Cloudy Day</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_bike.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike_type             0.0\n",
      "started_at            0.0\n",
      "ended_at              0.0\n",
      "start_station_name    0.0\n",
      "end_station_name      0.0\n",
      "customer_type         0.0\n",
      "trip_duration         0.0\n",
      "year                  0.0\n",
      "month                 0.0\n",
      "date                  0.0\n",
      "hour                  0.0\n",
      "day_start             0.0\n",
      "season                0.0\n",
      "temp                  0.0\n",
      "feelslike             0.0\n",
      "dew                   0.0\n",
      "humidity              0.0\n",
      "precip                0.0\n",
      "precipprob            0.0\n",
      "snow                  0.0\n",
      "snowdepth             0.0\n",
      "windspeed             0.0\n",
      "winddir               0.0\n",
      "sealevelpressure      0.0\n",
      "cloudcover            0.0\n",
      "visibility            0.0\n",
      "condition             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check percentage of null values\n",
    "print(clean_bike.isnull().mean() * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\n",
    "The analysis phase is still in progress..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
